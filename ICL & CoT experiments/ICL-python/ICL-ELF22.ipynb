{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d81bef15",
   "metadata": {},
   "source": [
    "## Example Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b88746d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: counterspeech\n",
      "  BD normally doesn‚Äôt sell through a 3rd party reseller. If BD doesn‚Äôt have it available, you can check eBay.\n",
      "  You can wait years to slowly progress in pain or just pay money regularly to progress regularly\n",
      "  Massacre missions don‚Äôt stack. The kills count one mission at a time  Only way you can really ‚Äústack‚Äù them is with a wing all sharing wing massacre missions\n",
      "  CHIA is for you to plot, and then set aside and forget.   Check it once every few days\n",
      "  Were all in this together  unless you don't wear a mask and you deserve to be beaten up with a hammer at home depot üôÑ\n",
      "Class: troll\n",
      "  That's makes you a thief.\n",
      "  Ok.  I will spare you.   But don't ask questions if you don't like the answers.\n",
      "  Hey OP, I read your comments and I don't think you should have done this regardless. Good luck with your mum.\n",
      "  Lol I hate you guys\n",
      "  Its really funny how you people react to an actual unpopular opinion. Tells me everything that needs to be said\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "label_column = 'Class'\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(f'../../Tasks/elf22/train.csv')\n",
    "train_df['length'] = train_df['text'].apply(lambda x: len(x))\n",
    "\n",
    "mapping = {1: \"troll\", 2: \"counterspeech\"}\n",
    "\n",
    "\n",
    "train_df[label_column] = train_df[label_column].apply(lambda x: mapping[x])\n",
    "\n",
    "context = \"\"\n",
    "for j in train_df[label_column].unique():\n",
    "\tprint(f'Class: {j}')\n",
    "\tsample = train_df[train_df['length'] < 180]\n",
    "\tsample = sample[sample[label_column] == j].sample(5)\n",
    "\tfor index, row in sample.iterrows():\n",
    "\t\tprint(f'  {row[\"text\"]}')\n",
    "\t\tcontext += f'<text_icl_begin> CONTEXT: {row[\"context\"]}\\nCOMMENT: {row[\"text\"]} <text_icl_end>\\nLABEL: {j}\\n'\n",
    "\n",
    "#save the context into a json file\n",
    "context = f\"You are an expert in social psychology.\\nAlways read the CONTEXT before the COMMENT and decide whether the comment is a TROLL or COUNTERSPEECH. Reply with the single label on its own line ‚Äî no extra words.\\n\\n### EXAMPLES\\n{context}### END EXAMPLES\"\n",
    "with open('../icl_promtps/elf22.json', 'w') as f:\n",
    "\tjson.dump([context], f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9996b42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "label_column = 'Class'\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(f'../elf22/train.csv')\n",
    "train_df['length'] = train_df['text'].apply(lambda x: len(x))\n",
    "\n",
    "mapping = {1: \"troll\", 2: \"counterspeech\"}\n",
    "\n",
    "\n",
    "train_df[label_column] = train_df[label_column].apply(lambda x: mapping[x])\n",
    "\n",
    "context = \"\"\n",
    "for j in train_df[label_column].unique():\n",
    "\tprint(f'Class: {j}')\n",
    "\tsample = train_df[train_df['length'] < 180]\n",
    "\tsample = sample[sample[label_column] == j].sample(5)\n",
    "\tfor index, row in sample.iterrows():\n",
    "\t\tprint(f'  {row[\"text\"]}')\n",
    "\t\tcontext += f'<text_icl_begin> CONTEXT: {row[\"context\"]}\\nCOMMENT: {row[\"text\"]} <text_icl_end>\\nLABEL: {j}\\n'\n",
    "\n",
    "#save the context into a json file\n",
    "context = f\"You are an expert in social psychology.\\nAlways read the CONTEXT before the COMMENT and decide whether the comment is a TROLL or COUNTERSPEECH. Reply with the single label on its own line ‚Äî no extra words.\\n\\n### EXAMPLES\\n{context}### END EXAMPLES\"\n",
    "with open('icl_promtps/elf22.json', 'w') as f:\n",
    "\tjson.dump([context], f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a3e7cd",
   "metadata": {},
   "source": [
    "### Pompt GPT-4o model and save results for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd3dd1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "with open('../icl_promtps/elf22.json', 'r') as f:\n",
    "\tdata = json.load(f)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce3617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai, json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import traceback, pickle\n",
    "\n",
    "import os, dotenv\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "client = openai.OpenAI(api_key = os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def get_response( message ): \n",
    "  \n",
    "    response = client.chat.completions.create(\n",
    "      model=\"chatgpt-4o-latest\",\n",
    "      # logprobs = True,\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert in social psychology.\"},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "      ],\n",
    "       max_tokens = 10,\n",
    "\n",
    "    )\n",
    "    # print(response.choices[0].message.content)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def get_inference(message, label_set):\n",
    "    \n",
    "\tpred = \"unknown\"\n",
    "\tfor i in range(6):\n",
    "\t\ttry:\n",
    "\t\t\tz = get_response(message)\n",
    "\t\t\tif z.strip().lower() in label_set:\n",
    "\t\t\t\tpred = z\n",
    "\t\t\t\tbreak\n",
    "\t\texcept:\n",
    "\t\t\tprint(traceback.format_exc())\n",
    "\t\t\tpass\n",
    "\n",
    "\treturn pred\n",
    "\n",
    "df = pd.read_csv(f'../../Tasks/elf22/test.csv')\n",
    "df = df.dropna(subset=['text'])\n",
    "mapping = {1: \"troll\", 2: \"counterspeech\"}\n",
    "label_column = 'Class'\n",
    "\n",
    "df[label_column] = df[label_column].apply(lambda x: mapping[x])\n",
    "\n",
    "for i in range(4):\n",
    "\n",
    "\tfor index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "\n",
    "\t\tprompt = f\"{data}\\n\\nCONTEXT: {row['context']}\\nTEXT:{row['text']}\\nLABEL:\"\n",
    "\t\t\n",
    "\t\tresponse = get_inference(prompt, label_set=list(mapping.values()))\n",
    "\t\tdf.at[index, 'predicted_label'] = response\n",
    "\n",
    "\tdf.to_csv(f'outputs/elf22/test_{i}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3034008d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg 0.6507261239111524\n",
      "Std 0.005180579221205069\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "f1_scores = []\n",
    "for i in range(4):\n",
    "\tdf = pd.read_csv(f'outputs/elf22/test_{i}.csv')\n",
    "\tf1_scores += [f1_score(df['Class'], df['predicted_label'], average='macro')]\n",
    "\t\n",
    "print('Avg', np.mean(f1_scores))\n",
    "print('Std', np.std(f1_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_torch-lastest (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
